{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is writen to find a ball in which we want to impose dissipation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to load that data, divide each component by its std and then plot the norm. It is as simple as that, and I already have all the codes that is needed for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('./../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ProcessFunctions import find_Aisv2,Find_a_i,find_Aisv2_onlyv\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns \n",
    "import cte_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_final=10500\n",
    "Ntout=cte_eq.Ntout\n",
    "Nxout=cte_eq.Nxout\n",
    "drs=0.012\n",
    "data_dir='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/MainSimulation2D_Tf'+str(T_final)+\"Nt=\"+str(Ntout)+\"Nx=\"+str(Nxout)+'PODonlyonV'+'drs'+str(drs)+\".npz\"\n",
    "PODmodes=np.load(data_dir)\n",
    "U_v=PODmodes['U']\n",
    "S_v=PODmodes['S']\n",
    "# VT_v=PODmodes['VT']\n",
    "q_bar_v=PODmodes['q_bar']\n",
    "Nt2=127534 # This is the number os snapshots used to find the POD, it is fined in the RunForward2D.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading POD modes\n",
    "\n",
    "\n",
    "data_dir='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/MainSimulation2D_Tf'+str(T_final)+\"Nt=\"+str(Ntout)+\"Nx=\"+str(Nxout)+'PODonlyontheta'+'drs'+str(drs)+\".npz\"\n",
    "\n",
    "PODmodes=np.load(data_dir)\n",
    "U_theta=PODmodes['U']\n",
    "S_theta=PODmodes['S']\n",
    "# VT_theta=PODmodes['VT']\n",
    "q_bar_theta=PODmodes['q_bar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from \"/central/groups/astuart/hkaveh/Data/LearnROM/transfer/SampleSimulation_Tf_2D'+str(T_final_run)+\"Nt=\"+str(cte_eq.Ntout)+\"N_m\"+str(N_m)+\"coeff\"+str(coeff)+\"number\"+str(index)\"\n",
    "T_final_run = 350 # each initial condition is simulated for 250 years\n",
    "Nt=5     # it is recorded every Nt time stes\n",
    "N_m_v=20 # number of modes that they have considered\n",
    "N_m_theta=20 # number of modes that they have considered\n",
    "coeff=1 # How the inital conditions are from the chaotic attractor\n",
    "number=10 # Which one do you want to load\n",
    "N_cut=2000\n",
    "# loading time series:\n",
    "N_m_load=30\n",
    "\n",
    "X_full=np.empty((1,N_m_load*2))\n",
    "Y_full=np.empty((1,N_m_load*2))\n",
    "\n",
    "\n",
    "for number in range(1,100):\n",
    "    data_dir='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/SampleSimulation_Tf_2D'+str(T_final_run)+\"Nt=\"+str(cte_eq.Ntout)+\"N_m\"+str(N_m_load)+\"coeff\"+str(coeff)+\"number\"+str(number)+\".npz\"\n",
    "    data_smaple=np.load(data_dir)\n",
    "\n",
    "    V_ox=data_smaple['array1']\n",
    "    theta_ox=data_smaple['array2']\n",
    "    t_ox=data_smaple['array3']\n",
    "    # removing data with probability p\n",
    "    # xi=100\n",
    "    # p_remove=np.tanh(xi*np.max(V_ox,axis=1))\n",
    "    # Nt_sample=p_remove.shape[0]\n",
    "    # print( \"number of points in this member is:\", Nt_sample)\n",
    "    # keep_mask_sample=np.random.rand(Nt_sample) > p_remove\n",
    "    # We work with log10 of V_ox and theta_ox:\n",
    "    V_ox=np.log10(V_ox)\n",
    "    theta_ox=np.log10(theta_ox)\n",
    "    A_v,P_v=find_Aisv2_onlyv(U_v,V_ox,q_bar_v,N_m_load) # you dont need P in general, but I need it to check if I do everything correctly\n",
    "    A_theta,P_theta=find_Aisv2_onlyv(U_theta,theta_ox,q_bar_theta,N_m_load)\n",
    "    # concatenating the two arrays\n",
    "    A=np.concatenate((A_v,A_theta),axis=1)\n",
    "    X_onesimulation=A[:-1,:]         # current step\n",
    "    Y_onesimulation=A[1:,:]-A[:-1,:] # next step minus the current step\n",
    "    print(\"shape of X_onesimulation before is\",X_onesimulation.shape)\n",
    "    # X_onesimulation=X_onesimulation[keep_mask_sample[:-1]]\n",
    "    # Y_onesimulation=Y_onesimulation[keep_mask_sample[:-1]]\n",
    "    print(\"shape of X_onesimulation after is\",X_onesimulation.shape)\n",
    "\n",
    "    X_full=np.append(X_full,X_onesimulation,axis=0)\n",
    "    Y_full=np.append(Y_full,Y_onesimulation,axis=0)\n",
    "    print(\"number is \" +str(number)+ \" size of data in this simulation is \" +str(X_onesimulation.shape[0])+\" total size is \" + str(X_full.shape[0]))\n",
    "\n",
    "# removing the first row which is empty\n",
    "X_full=X_full[1:,:]\n",
    "Y_full=Y_full[1:,:]\n",
    "\n",
    "# print(np.max(X_full))\n",
    "print(np.max(Y_full))\n",
    "# Loading the the numpy arrays Input and Output which are generated for imposing dissipiation far away from the attractor\n",
    "# # commenting here:\n",
    "# data_dir=\"/central/groups/astuart/hkaveh/Data/LearnROM/EllipticShell_radi_outer\"+str(radi_outer)+\"radi_inner\"+str(radi_inner)+\"PODappliedseperately.npz\"\n",
    "\n",
    "# data_smaple=np.load(data_dir)\n",
    "# Input_X=data_smaple['Input']\n",
    "# Output_Y=data_smaple['Output']\n",
    "# # appending the Input_X to the X_full and Output_Y to the Y_full\n",
    "# # appending the Input_X to the X_full and Output_Y to the Y_full, but append from the begining of the array\n",
    "# print(np.max(Output_Y))\n",
    "# X_full=np.append(Input_X,X_full,axis=0)\n",
    "# Y_full=np.append(Output_Y,Y_full,axis=0)\n",
    "# # untill here\n",
    "\n",
    "# deleting some colomns from X_full and Y_full that are should not be included based on N_m_v and N_m_theta\n",
    "# index of the columns that should be deleted\n",
    "index_delete=np.array([])\n",
    "if N_m_v<N_m_load:\n",
    "    index_delete=np.append(index_delete,np.arange(N_m_v,N_m_load))\n",
    "if N_m_theta<N_m_load:\n",
    "    index_delete=np.append(index_delete,np.arange(N_m_load+N_m_theta,2*N_m_load))\n",
    "\n",
    "\n",
    "# Convert the array elements to integers\n",
    "index_delete = index_delete.astype(int)\n",
    "\n",
    "X_full=np.delete(X_full,index_delete,axis=1)\n",
    "Y_full=np.delete(Y_full,index_delete,axis=1)\n",
    "print(\"index of the columns that are deleted are:\")\n",
    "print(index_delete)\n",
    "\n",
    "print(X_full.shape)\n",
    "print(\"size of the data is \" +str(X_full.shape[0]))\n",
    "# 50, 55, 59, 63, 72, 73,79,81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_onesimulation[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading POD modes for V and Theta\n",
    "N_m_v_load=30\n",
    "N_m_theta_load=30\n",
    "data_dir='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/MainSimulation2D_Tf'+str(T_final)+\"Nt=\"+str(Ntout)+\"Nx=\"+str(Nxout)+'PODonlyonV'+'drs'+str(drs)+\".npz\"\n",
    "PODmodes=np.load(data_dir)\n",
    "U_v=PODmodes['U']\n",
    "S_v=PODmodes['S']\n",
    "# VT_v=PODmodes['VT']\n",
    "q_bar_v=PODmodes['q_bar']\n",
    "Sigma_v=np.diagonal(S_v)\n",
    "Lambda_v=Sigma_v**2/Nt2\n",
    "Lambda_v=np.atleast_2d(Lambda_v[:N_m_v])\n",
    "Sigma_v=(np.sqrt(Lambda_v))\n",
    "\n",
    "\n",
    "data_dir='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/MainSimulation2D_Tf'+str(T_final)+\"Nt=\"+str(Ntout)+\"Nx=\"+str(Nxout)+'PODonlyontheta'+'drs'+str(drs)+\".npz\"\n",
    "PODmodes=np.load(data_dir)\n",
    "U_theta=PODmodes['U']\n",
    "S_theta=PODmodes['S']\n",
    "# VT_theta=PODmodes['VT']\n",
    "q_bar_theta=PODmodes['q_bar']\n",
    "Sigma_theta=np.diagonal(S_theta)\n",
    "# Nt2=PODmodes['VT'].shape[0]\n",
    "Lambda_theta=Sigma_theta**2/Nt2\n",
    "Lambda_theta=np.atleast_2d(Lambda_theta[:N_m_theta])\n",
    "Sigma_theta=(np.sqrt(Lambda_theta))\n",
    "# you need to save Sigma_theta and Sigma_v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_m_theta_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_v=Sigma_v[0,:N_m_v]\n",
    "Sigma_theta=Sigma_theta[0,:N_m_theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just added\n",
    "alpha_v=X_full[:,:N_m_v]\n",
    "alpha_theta=X_full[:,N_m_v:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if this compatible with the thing.\n",
    "print(Sigma_v.shape)\n",
    "print(Sigma_theta.shape)\n",
    "print(alpha_v.shape)\n",
    "print(alpha_theta.shape)\n",
    "print(Nt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_alpha_v=alpha_v/Sigma_v [np.newaxis,:]\n",
    "normalized_alpha_theta=alpha_theta/Sigma_theta [ np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_alpha=np.append(normalized_alpha_v,normalized_alpha_theta,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(normalized_alpha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the timeseries of the norm of the normalized_alpha\n",
    "norm_normalized_alpha=np.linalg.norm(normalized_alpha,axis=1)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(norm_normalized_alpha)\n",
    "plt.title(\"Norm of the normalized_alpha\")\n",
    "plt.xlabel(\"iteration\")\n",
    "# plt.xlim([0,1500])\n",
    "# plt.ylim([0,100])\n",
    "\n",
    "plt.ylabel(\"Norm of the normalized_alpha\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_normalized_alpha.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving Sigma_v and Sigma_theta adding informtion like Ntout,Nxout and T_final in directory\n",
    "directory='/central/groups/astuart/hkaveh/Data/LearnROM/transfer/'+'sigma'+str(T_final)+\"Nt=\"+str(Ntout)+\"Nx=\"+str(Nxout)+'PODonlyonV'+'drs'+str(drs)+\".npz\"\n",
    "np.savez(directory,Sigma_v=Sigma_v,Sigma_theta=Sigma_theta,Nt2=Nt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Sigma_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Sigma_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The ball seems to have a radi of 12."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
